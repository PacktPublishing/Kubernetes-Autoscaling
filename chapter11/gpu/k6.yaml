apiVersion: batch/v1
kind: Job
metadata:
  name: gpu-inference-load-test
spec:
  template:
    spec:
      containers:
      - name: k6
        image: grafana/k6:latest
        command: ["k6", "run", "/scripts/k6-load-test.js"]
        env:
        - name: K6_OUT
          value: "experimental-prometheus-rw"
        - name: K6_PROMETHEUS_RW_SERVER_URL
          value: "http://prometheus-operated.monitoring.svc.cluster.local:9090/api/v1/write"
        volumeMounts:
        - name: k6-script
          mountPath: /scripts
        resources:
          requests:
            memory: "512Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
      volumes:
      - name: k6-script
        configMap:
          name: gpu-inference-load-test-script
      restartPolicy: Never
  backoffLimit: 4
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: gpu-inference-load-test-script
data:
  k6-load-test.js: |
    import http from 'k6/http';
    import { check, sleep } from 'k6';
    import { Rate } from 'k6/metrics';

    // Custom metrics
    const errorRate = new Rate('errors');

    // Test configuration
    export const options = {
      // Define different test scenarios
      scenarios: {
        // Warm-up phase
        warmup: {
          executor: 'constant-vus',
          vus: 1,
          duration: '30s',
          tags: { phase: 'warmup' },
        },
        // Load testing phase
        load_test: {
          executor: 'ramping-vus',
          startTime: '30s',
          stages: [
            { duration: '2m', target: 10 },   // Ramp up to 10 users
            { duration: '5m', target: 10 },   // Stay at 10 users
            { duration: '2m', target: 20 },   // Ramp up to 20 users
            { duration: '5m', target: 20 },   // Stay at 20 users
            { duration: '2m', target: 50 },   // Spike to 50 users
            { duration: '5m', target: 50 },   // Stay at 50 users
            { duration: '3m', target: 0 },    // Ramp down
          ],
          tags: { phase: 'load_test' },
        },
      },
      // Performance thresholds
      thresholds: {
        http_req_duration: ['p(95)<3000'], // 95% of requests under 3s
        http_req_failed: ['rate<0.05'],    // Error rate under 5%
        checks: ['rate>0.95'],             // 95% of checks should pass
      },
    };

    // Base URL - update this to your service endpoint
    const BASE_URL = 'http://gpu-inference-service.default.svc.cluster.local';

    // Create a simple test image (base64 encoded 1x1 pixel PNG)
    const testImageData = 'iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8/5+hHgAHggJ/PchI7wAAAABJRU5ErkJggg==';

    export default function() {
      // Health check
      const healthResponse = http.get(`${BASE_URL}/health`);

      check(healthResponse, {
        'health check status is 200': (r) => r.status === 200,
        'health check response time < 500ms': (r) => r.timings.duration < 500,
      }) || errorRate.add(1);

      // Create form data for image upload with base64 encoding (k6-compatible)
      const formData = {
        image: http.file(testImageData, 'test.png', 'image/png', { encoding: 'base64' }),
      };

      // Make prediction request
      const predictionResponse = http.post(`${BASE_URL}/predict`, formData, {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
      });

      const checkResult = check(predictionResponse, {
        'prediction status is 200': (r) => r.status === 200,
        'prediction response time < 5000ms': (r) => r.timings.duration < 5000,
        'prediction response contains result': (r) => {
          try {
            const json = JSON.parse(r.body);
            return json.predicted_class !== undefined;
          } catch {
            return false;
          }
        },
      });

      if (!checkResult) {
        console.log(`Request failed: Status ${predictionResponse.status}, Body: ${predictionResponse.body}`);
        errorRate.add(1);
      }

      // Wait between requests (simulating user think time)
      sleep(Math.random() * 2 + 1); // Random sleep between 1-3 seconds
    }

    // Setup function (runs once at the beginning)
    export function setup() {
      console.log('Starting GPU inference load test');
      console.log(`Base URL: ${BASE_URL}`);

      // Verify the service is accessible
      const healthCheck = http.get(`${BASE_URL}/health`);
      if (healthCheck.status !== 200) {
        console.error('Service health check failed, aborting test');
        return null;
      }

      console.log('Service health check passed, proceeding with test');
      return {};
    }

    // Teardown function (runs once at the end)
    export function teardown(data) {
      console.log('GPU inference load test completed');
    }
