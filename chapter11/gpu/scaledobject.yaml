apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: image-processing-app
  namespace: default
spec:
  scaleTargetRef:
    name: image-processing-app
  minReplicaCount: 1
  maxReplicaCount: 5
  advanced:
    horizontalPodAutoscalerConfig:
      behavior:
        scaleUp:
          stabilizationWindowSeconds: 0
          policies:
          - type: Percent
            value: 100
            periodSeconds: 5
        scaleDown:
          stabilizationWindowSeconds: 120
          policies:
          - type: Percent
            value: 100
            periodSeconds: 30
  triggers:
  # Scale based on average request rate
  - type: prometheus
    metadata:
      serverAddress: http://prometheus-operated.monitoring.svc.cluster.local:9090
      metricName: gpu_inference_request_rate
      threshold: '40'  # Scale up when more than 40 requests per second
      query: sum(rate(gpu_inference_requests_total{exported_endpoint="/predict",status="200"}[2m]))
  # Scale based on request latency (performance degradation)
  - type: prometheus
    metadata:
      serverAddress: http://prometheus-operated.monitoring.svc.cluster.local:9090
      metricName: gpu_inference_latency_p95
      threshold: '2'  # Scale up when P95 latency > 2s
      query: sum(histogram_quantile(0.95, rate(gpu_inference_request_duration_seconds_bucket{pod=~"image-processing-app-.*"}[2m])))